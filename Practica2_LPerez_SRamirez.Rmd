---
title: 'Práctica 2: Limpieza y validación de los datos'
author: "Luis Manuel Pérez Geraldino y Sergi Ramirez Mitjans"
date: "16/5/2019"
output:
  html_document:
    df_print: paged
---

```{r, echo = FALSE}
# Instalar paquetes de R que necesitaremos
RequiredPackages <- c("Hmisc", "dplyr", 'VIM', 'FactoMineR', 'tidyr', 'dplyr', 'magrittr', 'plspm', 'amap')
for (i in RequiredPackages) { #Installs packages if not yet installed
    if (!require(i)) install.packages(i)
}

# Insertamos las rutas para poder ejecutar el scripts 
ruta <- 'C:/Users/sergir/Desktop/vademecum-consolidation-master/'
archivo <- 'result.csv'
path <- paste0(ruta, archivo)
```


# 1. Descripción del dataset

El dataset que a continuación se va a describir, se a obtenido mediante *web scrapping* en la práctica 1 de esta misma asignatura por lo tanto está práctica se tratará de realizar la limpieza del dataset que se consiguió desarrollar en etapas anteriores de esta asignatura. 

El conjunto de datos obtenido recoge los medicamentos con más facturación en el mundo farmacéutico. A la vez también esta incorporado los medicamentos más consumidos en España. Este dataset es variable ya que se tendrán tantos medicamentos como el código demande. Esto es posible ya que el código esta preparado para hacer de buscador y extractor de aquellos medicamentos que se pasen por parámetros. Algunas variables de las que encontramos en el dataset sería el precio, nombre del medicamente, genérico o url del Vademecum.

```{r}
# Leemos los datos para guardar
datos <- read.csv2(path,  sep = ";", header = T, stringsAsFactors = T, dec = ".", encoding = 'latin1')

# Cambiamos el nombre de las columnas para que puedan ser leibles
cols <- c("Medicamento", "URL", "Presentacion", "Codigo_Nacional", "Tipo", "Generico", "Laboratorio", "Estado", "Fecha_Alta", "Fecha_Baja", "Aportacion_Beneficiario", "Principio_Activo", "PVP", "Precio_Referencia", "Menor_Precio_Agrupacion_Homogenea", "Agrupacion_Homogenea", "Diagnostico_Hospitalario", "Tratamiento_Larga_Duracion", "Control_Medico", "Huerfano", "Enfermedad")

colnames(datos) <- cols

# Generamos el archivo metadata
library(Hmisc)
metadata <- contents(datos)
html(metadata)

# Generamos 3 vectores con la posicion de las columnas según la tipologia de ellas
lista_clase <- sapply(datos, class)
table(lista_clase)

# Generamos diferentes variables
var_factor    <- unname(which(lista_clase == 'factor'))
var_numeric   <- unname(which(lista_clase %in% c('numeric', 'integer')))
```

# 2. Integración y selección de datos

En esta fase se tratará de 

## 2.1 Conversión de la tipologia de la variable

```{r}
# Convertimos las variables a character
# cols <- colnames(datos)[which(!var_factor %in% 7:8)]

cols <- c("Medicamento", "URL", "Presentacion", "Codigo_Nacional", "Tipo", "Generico", "Laboratorio", "Estado", "Aportacion_Beneficiario", "Principio_Activo","Agrupacion_Homogenea", "Fecha_Alta", "Fecha_Baja", "Diagnostico_Hospitalario", "Tratamiento_Larga_Duracion", "Control_Medico", "Huerfano", "Enfermedad")

for(i in cols){
  cat("Transformando variable", i, "...")
  datos[, i] <- as.character(datos[, i])
  cat(" OK\n")
}
 
```

## 2.2. Creamos nuevas variables
```{r}
# Separamos el código de la agrupación
codigos <- strsplit(as.character(datos[, 'Agrupacion_Homogenea']), "-")
data = data.frame(codigo = character(), agrupacion = character(), stringsAsFactors=FALSE)

for (i in 1:length(codigos)){
    if(codigos[i][1] == ""){
      data[i, 1] = NA
      data[i, 2] = NA
    } else {
      data[i, 1] = as.character(codigos[[i]][1])
      data[i, 2] = as.character(codigos[[i]][2])
    }
}

datos[, 'Codigo_Agrupacion'] <- data[, 'codigo']

# Realizamos la separación por laboratorio
lab <- strsplit(as.character(datos[, 'Laboratorio']), ",")
data = data.frame(codigo = character(), laboratorio = character(), sociedad =  character(), stringsAsFactors = FALSE)

for (i in 1:length(codigos)){
    if(length(lab[[i]]) == 3){
      valor1 = as.character(lab[[i]][1])
      valor2 = as.character(lab[[i]][2])
      valor3 = as.character(lab[[i]][3])
    } else {
      if (length(lab[[i]]) == 2){
      valor1 = as.character(lab[[i]][1])
      valor2 = as.character(lab[[i]][2])
      valor3 = ""
      } else {
      valor1 = ""
      valor2 = as.character(lab[[i]][2])
      valor3 = ""
      }
    }
    data[i, 1] = valor1
    data[i, 2] = valor2
    data[i, 3] = valor3
}

datos[, 'Codigo_Laboratorio'] <- data[, 'codigo']

# Creamos la variable Baja que consiste en si el medicamento esta o no esta dado de baja
datos[, 'Baja'] <- ifelse(datos[, 'Fecha_Baja'] == "", "NO", "SI")
```

### Selección de los datos de interés

```{r}
cols <- c("Codigo_Nacional", "Medicamento", "Presentacion", "Tipo", "Laboratorio", "Estado", "Aportacion_Beneficiario", 'Principio_Activo', "PVP", "Agrupacion_Homogenea", "Tratamiento_Larga_Duracion", "Enfermedad", "Baja",'Codigo_Laboratorio', 'Codigo_Agrupacion')

BBDD_seleccion <- datos[, which(colnames(datos) %in% cols)]
```

# 3. Limpieza de datos

OJO: Dependiendo de si hacemos esta fase antes que la seleccion de variables o no deberemos explicar el tema de la imputación de los valores faltantes en las variables numéricas y la imputación de los valores de las variables categóricas.  Decir que hemos eliminado las variables de fecha, la Genérico por ser toda NA's y la variables de precios por no necesitarlas además de contener NA's. Comentar si las quisieramos cuales serian sus procesos de tratamiento. 


Por lo tanto, nos replanteamos la idea de imputar las variables `Precio_Referencia` y `Menor_Precio_Agrupacion_Homogenea`. Eliminamos la variable `Generico` ya que el 100% corresponde a NA's.

```{r}
# Eliminamos la variable Generico de nuestro conjunto de datos
datos[, 'Generico'] <- NULL
```

A continuación hacemos que todos los códigos tengan el mismo número de dígitos. 

```{r}
table(nchar(datos[, 'Codigo_Nacional']))
table(nchar(datos[, 'Codigo_Laboratorio']))
datos[, 'Codigo_Laboratorio'] <- sprintf("%0.4d", as.numeric(datos[, 'Codigo_Laboratorio']))
table(nchar(datos[, 'Codigo_Agrupacion']))
datos[, 'Codigo_Agrupacion'] <- sprintf("%0.5d", as.numeric(datos[, 'Codigo_Agrupacion']))
```

Como tenemos en variables numéricas valores NA's deberemos de imputar estos registros para obtener los que realmente se consideren más cercanos. Para ello utilizaremos un método de imputación llamado *MICE*.

```{r}
# https://www.analyticsvidhya.com/blog/2016/03/tutorial-powerful-packages-imputing-missing-values/

# http://rpubs.com/ydmarinb/429757

# https://rpubs.com/medusa/128029

# 1) Primero vamos a ver los patrones
aggr(datos, prop=FALSE, 
     numbers=TRUE, border=NA,
     combine=TRUE)


library(VIM)
library(FactoMineR)
library(tidyr)
library(dplyr)
library(magrittr)
library(mice)

variables <- c(var_numeric)
Datos_imputados <- mice(datos[, names(datos) %in% colnames(datos)[variables]]
, m=5, seed = 2018)

Datos_imputados <- mice(datos[, names(datos) %in% colnames(datos)[variables]])
completeData <- complete(Datos_imputados)

aggr(completeData)
```

Como sabemos que nuestra variable categórica contiene el valor "-" que representa NA's vamos a tratarlos para que aparezcan como NA's

```{r}
# Tratamos el valor "-" de la variable 'Agrupacion_Homogenea' como dato faltante
quienes <- which(BBDD_seleccion['Agrupacion_Homogenea'] == "-")
BBDD_seleccion[quienes, 'Agrupacion_Homogenea'] <- NA
```

A continuación y para realizar una correcta limpieza de los datos comprobamos como esta nuesto dataframe. 

```{r}
# Generamos el archivo metadata
metadata2 <- Hmisc::contents(BBDD_seleccion)
html(metadata2)
```

## 3.1. Ceros y elementos vacíos

Primero de todo vamos a mirar donde tenemos NA's y cuantos NA's hay por cada variable.

```{r}
NAs <- data.frame(absoluto = colSums(is.na(BBDD_seleccion)))
NAs[, 'porcentaje'] <- round((NAs$absoluto/nrow(BBDD_seleccion))*100, 2)
NAs
```

Vemos como obtenemos un 5% de valores perdidos en la variable `Agrupacion_Homogenea` y la variable que deriva de ella `Codigo_Agrupacion`. Por lo tanto deberemos de tratarla para que desaparezcan este porcentaje de NA's. 

Para ello crearemos una nueva categoria de la variable que sea `99999 - SIN AGRUPACION`.
```{r}
qui2 <- which(is.na(BBDD_seleccion[, 'Codigo_Agrupacion']))
BBDD_seleccion[qui2, 'Codigo_Agrupacion'] <- '99999'
qui2 <- which(is.na(BBDD_seleccion[, 'Agrupacion_Homogenea']))
BBDD_seleccion[qui2, 'Agrupacion_Homogenea'] <- '99999 - SIN AGRUPACION'
```

Volvemos a comprobar que hayamos eliminado los valores perdidos que obtenemos de nuestra base de datos. 

```{r}
NAs <- data.frame(absoluto = colSums(is.na(BBDD_seleccion)))
NAs[, 'porcentaje'] <- round((NAs$absoluto/nrow(BBDD_seleccion))*100, 2)
NAs
```

## 3.2. Valores extremos

A continuación vamos a calcular si tenemos valores extremos para ello vemos la variable numérica mediante un boxplot. 

```{r}
fill <-  "#4271AE" 
line <-  "#1F3552"

par(mfrow= c (1,2), mar = c(5,4,2,1))
p10 <- ggplot(data = BBDD_seleccion, aes(x = "", y = PVP))  + 
       geom_boxplot (fill = fill , color = line) +
        ggtitle ( "PVP" )
p10

dotchart(BBDD_seleccion$PVP, xlab = "PVP",  ylab = "Orden de los datos")
par(mfrow= c (1,1))
```

Como podemos comprobar tenemos Outliers. Deberemos de trabajar con ellos. 

```{r}
boxplot.stats(datos$PVP)$out
shapiro.test(datos$PVP)
shapiro.test(log(datos[,'PVP']))
shapiro.test(sqrt(datos[,'PVP']))
```

Como vemos en nuestros contrastes, podemos decir que tanto los datos originales como los datos en formato de logaritmo tienen poca normalidad. Por ello lo que vamos hacer es sospechas de que existe 2 grupos diferenciados uno que serian aquellos medicamentos que tienen un coste muy elevado ya que són tratamientos específicos para enfermedades importantes y otro conjunto de datos que tienen un precio más asequible para la población. 

Contrastemos esta idea que acabamos de plantear. 

Para ello vamos a separar en dos conjuntos. El primer conjunto seran todos los valores que esten por debajo del tercer quartil y el segundo grupo aquellos conjuntos de datos que esten por encima de este valor. 

```{r}
valor_corte <- quantile(datos[, 'PVP'], 0.75)
quienes <- which(datos[, 'PVP'] <= valor_corte)

p10 <- ggplot(data = BBDD_seleccion[-quienes, ], aes(x = "", y = PVP))  + 
       geom_boxplot (fill = fill , color = line) +
        ggtitle ( "PVP" )
p10
# Comprovamos el test por grupos
shapiro.test(datos[-quienes, 'PVP'])
shapiro.test(log(datos[-quienes,'PVP']))
shapiro.test(sqrt(datos[-quienes,'PVP']))
```



# 4. Análisis de los datos

## 4.1. Selección de grupos de datos a analizar

## 4.2 Comprobación de normalidad y homogeneidad de la varianza

```{r}
library(nortest)
alpha = 0.05
col.names = colnames(datos)
for (i in 1:ncol(datos)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n")
  if (is.integer(datos[,i]) | is.numeric(datos[,i])) {
    p_val = ad.test(datos[,i])$p.value
    if (p_val < alpha) {
      cat("  - ")
      cat(col.names[i])
      cat("\n")
    }
  }
}

library(arules)
datos$Categoria_PVP <- discretize(datos$PVP, labels = c('A', 'B', 'C'))
```

```{r}
fligner.test(PVP ~ Categoria_PVP, data = datos)
```

## 4.3. Pruebas estadísticas

### 4.3.1. ¿Existen diferencias en el precio según el tipo de medicamento? 

Para realizar este contraste, deberemos de realizar una ANOVA a partir de una función lineal.

```{r}
variable.respuesta = 'PVP'
variable.explicativa = 'Tipo'

modelo <- lm(variable.respuesta ~  as.factor(variable.explicativa), data = datos)

```


### 4.3.2. ¿El precio del medicamento es influido por el laboratorio que lo genera?

```{r}

```

### 4.3.3. Modelo de predicción del precio

A continuación vamos a realizar un modelo predictivo del precio según las demás variables del modelo.

```{r}

BBDD_seleccion[, 'log_PVP'] <- log(BBDD_seleccion[, 'PVP'])

# A continuación generamos nuestro modelo lineal. Para ello primero de todo vamos a hacer los pasos de stepwise para que se escojan automaticamente aquellas variables que sean importantes para el modelo. 

library(MASS)

cols <- c("log_PVP", 'Presentacion', 'Tipo', 'Estado', 'Aportacion_Beneficiario', 'Tratamiento_Larga_Duracion', 'Enfermedad', 'Codigo_Laboratorio', 'Baja')

dataRegresion <- BBDD_seleccion[, cols]

for(i in colnames(dataRegresion)){
  if(i != 'log_PVP'){
    dataRegresion[, i] <- as.factor(dataRegresion[, i])
  }
}

full.model <- lm(log_PVP ~ ., data = dataRegresion)
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)

# =============================================================================================================
# También realizamos el modelo a través de PLS (Regresión de mínimos cuadrados parciales)
library(plspm)
x <- dataRegresion[, which(!colnames(dataRegresion) %in% "PVP")]
y <- dataRegresion$log_PVP
modelo <- plspm::plsreg1(x, y, nc = 10, cv = TRUE)


```



### 4.3.4. Recomendador de medicamentos

En este caso cambiamos nuestra variable respuesta y actualmente seria el nombre del producto como variable respuesta. 

```{r}
# Nos quedamos con los datos necesarios
dataTree <- BBDD_seleccion

# Primero de todo transformamos los numericos en categoricos

# Dividimos la muestra en train and test
#Sample Indexes
indexes = sample(1:nrow(data), size=0.2*nrow(data))

```


# 5. Representación de resultados

# 6. Resolución del problema

# 7. Futuras lineas de trabajo

A continuación se detallarán futuras lineas de trabajo que se podrian realizar a partir de los datos que se han analizado. Decir que estas futuras lineas de trabajo se deberian de adecuar a las necesidades de cada usuario de los datos por lo tanto puede ser que para según quien use estos datos no le hagan falta algunas de las propuestas que se utilizarán a continuación:

  - Generar, a partir del modelo predictivo del árbol de decisión, un app que le permita a cualquier usuario médico encontrar rápidamente el medicamento mas adecuado para cada paciente.
  -
  -
  -
  -

# 8. Código

El código del proyecto se encuentra en el repositorio libre de Github. [Enlace](https://github.com/lmgeraldino/vademecum-consolidation).

